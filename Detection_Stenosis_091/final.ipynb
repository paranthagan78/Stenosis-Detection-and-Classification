{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc304a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tqdm as notebook_tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c44edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define paths - using relative paths\n",
    "BASE_DIR = \".\"\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"dataset\")\n",
    "COCO_DIR = os.path.join(DATASET_DIR, \"coco_format\")\n",
    "YOLO_DIR = os.path.join(DATASET_DIR, \"yolo_format\")\n",
    "PROCESSED_DIR = os.path.join(DATASET_DIR, \"processed\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "\n",
    "# Create necessary directories\n",
    "for directory in [DATASET_DIR, YOLO_DIR, PROCESSED_DIR, RESULTS_DIR, MODEL_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# For YOLO format\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for subdir in [\"images\", \"labels\"]:\n",
    "        os.makedirs(os.path.join(YOLO_DIR, split, subdir), exist_ok=True)\n",
    "\n",
    "# For processed data\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(PROCESSED_DIR, split), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Check for GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")  # Use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee01850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define function to convert COCO to YOLO format\n",
    "def convert_all_datasets():\n",
    "    \"\"\"\n",
    "    Convert all datasets from COCO to YOLO format based on correct file paths\n",
    "    \"\"\"\n",
    "    # Update paths to work with the global variables\n",
    "    base_dir = os.path.join(BASE_DIR, \"dataset\", \"stenosis\")\n",
    "    output_base_dir = YOLO_DIR\n",
    "    \n",
    "    print(f\"Looking for COCO annotations in: {base_dir}\")\n",
    "    print(f\"Output YOLO annotations will be saved to: {output_base_dir}\")\n",
    "    \n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        coco_file = os.path.join(base_dir, split, \"annotations\", f\"{split}.json\")\n",
    "        output_dir = os.path.join(output_base_dir, split, \"labels\")\n",
    "        images_dir = os.path.join(base_dir, split, \"images\")\n",
    "        \n",
    "        print(f\"Checking for COCO file: {coco_file}\")\n",
    "        \n",
    "        if os.path.exists(coco_file):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Create image output directory\n",
    "            images_output_dir = os.path.join(output_base_dir, split, \"images\")\n",
    "            os.makedirs(images_output_dir, exist_ok=True)\n",
    "            \n",
    "            print(f\"Converting {split} dataset...\")\n",
    "            # Load COCO annotations\n",
    "            with open(coco_file, 'r') as f:\n",
    "                coco_data = json.load(f)\n",
    "            \n",
    "            # Create dictionary for image lookup\n",
    "            image_dict = {img['id']: img for img in coco_data['images']}\n",
    "            \n",
    "            # Find stenosis category id\n",
    "            stenosis_category_id = None\n",
    "            for category in coco_data['categories']:\n",
    "                if category.get('name', '').lower() == 'stenosis':\n",
    "                    stenosis_category_id = category['id']\n",
    "                    break\n",
    "            \n",
    "            if stenosis_category_id is None:\n",
    "                print(\"Warning: 'stenosis' category not found in the dataset.\")\n",
    "                print(\"Available categories:\", [cat.get('name', cat.get('id')) for cat in coco_data['categories']])\n",
    "                # Use first category if stenosis not found\n",
    "                stenosis_category_id = coco_data['categories'][0]['id']\n",
    "                print(f\"Using category ID {stenosis_category_id} as default\")\n",
    "            \n",
    "            # Process each annotation\n",
    "            annotation_count = 0\n",
    "            for ann in coco_data['annotations']:\n",
    "                # Skip if not stenosis\n",
    "                if ann['category_id'] != stenosis_category_id:\n",
    "                    continue\n",
    "                \n",
    "                img_info = image_dict[ann['image_id']]\n",
    "                img_width = img_info['width']\n",
    "                img_height = img_info['height']\n",
    "                \n",
    "                # Get bounding box coordinates\n",
    "                x, y, width, height = ann['bbox']\n",
    "                \n",
    "                # Convert to YOLO format (x_center, y_center, width, height) normalized\n",
    "                x_center = (x + width / 2) / img_width\n",
    "                y_center = (y + height / 2) / img_height\n",
    "                norm_width = width / img_width\n",
    "                norm_height = height / img_height\n",
    "                \n",
    "                # Ensure values are within bounds [0, 1]\n",
    "                x_center = max(0, min(1, x_center))\n",
    "                y_center = max(0, min(1, y_center))\n",
    "                norm_width = max(0, min(1, norm_width))\n",
    "                norm_height = max(0, min(1, norm_height))\n",
    "                \n",
    "                # Create YOLO format label (class 0 for stenosis)\n",
    "                yolo_line = f\"0 {x_center} {y_center} {norm_width} {norm_height}\\n\"\n",
    "                \n",
    "                # Save to label file\n",
    "                image_filename = img_info['file_name']\n",
    "                image_basename = os.path.splitext(image_filename)[0]\n",
    "                label_path = os.path.join(output_dir, f\"{image_basename}.txt\")\n",
    "                \n",
    "                # Append to label file (or create if it doesn't exist)\n",
    "                with open(label_path, 'a') as f:\n",
    "                    f.write(yolo_line)\n",
    "                \n",
    "                # Copy image if it doesn't exist in output directory\n",
    "                src_path = os.path.join(images_dir, image_filename)\n",
    "                dst_path = os.path.join(images_output_dir, image_filename)\n",
    "                if not os.path.exists(dst_path) and os.path.exists(src_path):\n",
    "                    shutil.copy2(src_path, dst_path)\n",
    "                \n",
    "                annotation_count += 1\n",
    "            \n",
    "            print(f\"Conversion complete for {split}. Processed {annotation_count} annotations.\")\n",
    "        else:\n",
    "            print(f\"COCO file {coco_file} not found. Skipping {split} split.\")\n",
    "    \n",
    "    # Create classes.txt file\n",
    "    classes_file = os.path.join(output_base_dir, \"classes.txt\")\n",
    "    with open(classes_file, 'w') as f:\n",
    "        f.write(\"stenosis\\n\")\n",
    "    \n",
    "    print(\"All datasets converted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36632c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define image preprocessing functions\n",
    "def apply_clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "    \"\"\"Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to enhance image contrast\"\"\"\n",
    "    if len(image.shape) == 3:  # Color image\n",
    "        # Convert to LAB color space\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "        # Split channels\n",
    "        l, a, b = cv2.split(lab)\n",
    "        # Create CLAHE object\n",
    "        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "        # Apply CLAHE to L-channel\n",
    "        cl = clahe.apply(l)\n",
    "        # Merge channels\n",
    "        merged = cv2.merge((cl, a, b))\n",
    "        # Convert back to BGR\n",
    "        enhanced = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "        return enhanced\n",
    "    else:  # Grayscale image\n",
    "        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "        return clahe.apply(image)\n",
    "\n",
    "def preprocess_image(image_path, output_path, target_size=(640, 640), convert_to_gray=False):\n",
    "    \"\"\"\n",
    "    Preprocess an angiographic image with multiple techniques\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        output_path: Path to save the processed image\n",
    "        target_size: Target image size as (width, height)\n",
    "        convert_to_gray: Whether to convert to grayscale\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Could not read image {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to grayscale if requested\n",
    "    if convert_to_gray:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Convert back to 3 channels for consistent processing\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Apply CLAHE for contrast enhancement\n",
    "    enhanced = apply_clahe(image, clip_limit=3.0)\n",
    "    \n",
    "    # Apply noise reduction (Gaussian filter)\n",
    "    denoised = cv2.GaussianBlur(enhanced, (5, 5), 0)\n",
    "    \n",
    "    # Normalize pixel values to range [0, 1]\n",
    "    normalized = denoised.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Convert back to uint8 for saving\n",
    "    processed = (normalized * 255).astype(np.uint8)\n",
    "    \n",
    "    # Resize to target size\n",
    "    if target_size:\n",
    "        processed = cv2.resize(processed, target_size)\n",
    "    \n",
    "    # Save the processed image\n",
    "    cv2.imwrite(output_path, processed)\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84181d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define dataset preprocessing function\n",
    "def preprocess_dataset(input_dir, output_dir, split=\"train\", target_size=(640, 640), convert_to_gray=False):\n",
    "    \"\"\"\n",
    "    Preprocess all images in a dataset split\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory containing the input images\n",
    "        output_dir: Directory to save the processed images\n",
    "        split: Dataset split (train, val, test)\n",
    "        target_size: Target image size\n",
    "        convert_to_gray: Whether to convert to grayscale\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(input_dir, split, \"images\")\n",
    "    labels_dir = os.path.join(input_dir, split, \"labels\")\n",
    "    \n",
    "    output_images_dir = os.path.join(output_dir, split, \"images\")\n",
    "    output_labels_dir = os.path.join(output_dir, split, \"labels\")\n",
    "    \n",
    "    os.makedirs(output_images_dir, exist_ok=True)\n",
    "    os.makedirs(output_labels_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each image\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=f\"Preprocessing {split} images\"):\n",
    "        # Preprocess and save the image\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        output_img_path = os.path.join(output_images_dir, img_file)\n",
    "        \n",
    "        preprocess_image(img_path, output_img_path, target_size, convert_to_gray)\n",
    "        \n",
    "        # Copy the corresponding label file if it exists\n",
    "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            output_label_path = os.path.join(output_labels_dir, label_file)\n",
    "            shutil.copy2(label_path, output_label_path)\n",
    "    \n",
    "    print(f\"Preprocessing complete for {split} split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define data augmentation function\n",
    "def augment_data(images_dir, labels_dir, output_images_dir, output_labels_dir, augmentation_factor=3):\n",
    "    \"\"\"\n",
    "    Augment training data with various transformations\n",
    "    \n",
    "    Args:\n",
    "        images_dir: Directory containing original images\n",
    "        labels_dir: Directory containing original labels\n",
    "        output_images_dir: Directory to save augmented images\n",
    "        output_labels_dir: Directory to save augmented labels\n",
    "        augmentation_factor: Number of augmented samples per original image\n",
    "    \"\"\"\n",
    "    os.makedirs(output_images_dir, exist_ok=True)\n",
    "    os.makedirs(output_labels_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy original files to output directories\n",
    "    for file in os.listdir(images_dir):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            shutil.copy2(os.path.join(images_dir, file), os.path.join(output_images_dir, file))\n",
    "            \n",
    "            # Copy corresponding label if it exists\n",
    "            label_file = os.path.splitext(file)[0] + '.txt'\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            if os.path.exists(label_path):\n",
    "                shutil.copy2(label_path, os.path.join(output_labels_dir, label_file))\n",
    "    \n",
    "    # Create augmentation pipeline\n",
    "    transform = A.Compose([\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.8),\n",
    "            A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.8),\n",
    "        ], p=1.0),\n",
    "        A.OneOf([\n",
    "            A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
    "            A.MedianBlur(blur_limit=5, p=0.5),\n",
    "        ], p=0.8),\n",
    "        A.OneOf([\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.Rotate(limit=15, p=0.5),\n",
    "        ], p=0.8),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.3),\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    \n",
    "    # Augment each image\n",
    "    for file in tqdm(os.listdir(images_dir), desc=\"Augmenting data\"):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(images_dir, file)\n",
    "            label_file = os.path.splitext(file)[0] + '.txt'\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            \n",
    "            if not os.path.exists(label_path):\n",
    "                continue\n",
    "            \n",
    "            # Read image and labels\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            # Parse YOLO labels\n",
    "            bboxes = []\n",
    "            class_labels = []\n",
    "            \n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        class_id = int(parts[0])\n",
    "                        x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                        bboxes.append([x_center, y_center, width, height])\n",
    "                        class_labels.append(class_id)\n",
    "            \n",
    "            if not bboxes:\n",
    "                continue\n",
    "            \n",
    "            # Generate augmented samples\n",
    "            for i in range(augmentation_factor):\n",
    "                try:\n",
    "                    transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "                    aug_image = transformed['image']\n",
    "                    aug_bboxes = transformed['bboxes']\n",
    "                    aug_class_labels = transformed['class_labels']\n",
    "                    \n",
    "                    # Save augmented image\n",
    "                    aug_filename = f\"{os.path.splitext(file)[0]}_aug{i}{os.path.splitext(file)[1]}\"\n",
    "                    cv2.imwrite(os.path.join(output_images_dir, aug_filename), aug_image)\n",
    "                    \n",
    "                    # Save augmented labels\n",
    "                    aug_label_filename = f\"{os.path.splitext(file)[0]}_aug{i}.txt\"\n",
    "                    with open(os.path.join(output_labels_dir, aug_label_filename), 'w') as f:\n",
    "                        for bbox, class_id in zip(aug_bboxes, aug_class_labels):\n",
    "                            f.write(f\"{class_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Augmentation failed for {file} (iteration {i}): {str(e)}\")\n",
    "    \n",
    "    print(f\"Data augmentation complete. Generated {augmentation_factor} augmented samples per original image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284efc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Define YAML configuration function\n",
    "def create_dataset_yaml(base_dir, train_path, val_path, test_path, yaml_path, class_names=None):\n",
    "    \"\"\"\n",
    "    Create a YAML configuration file for the dataset\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory for the project\n",
    "        train_path: Path to training data\n",
    "        val_path: Path to validation data\n",
    "        test_path: Path to test data\n",
    "        yaml_path: Path to save the YAML file\n",
    "        class_names: List of class names (default: [\"stenosis\"])\n",
    "    \"\"\"\n",
    "    if class_names is None:\n",
    "        # Try to read class names from classes.txt\n",
    "        classes_file = os.path.join(base_dir, \"dataset\", \"yolo_format\", \"classes.txt\")\n",
    "        if os.path.exists(classes_file):\n",
    "            with open(classes_file, 'r') as f:\n",
    "                class_names = [line.strip() for line in f.readlines()]\n",
    "        else:\n",
    "            class_names = [\"stenosis\"]\n",
    "    \n",
    "    # Create YAML content\n",
    "    yaml_content = {\n",
    "        \"path\": os.path.join(base_dir, \"dataset\"),\n",
    "        \"train\": os.path.join(train_path, \"images\"),\n",
    "        \"val\": os.path.join(val_path, \"images\"),\n",
    "        \"test\": os.path.join(test_path, \"images\"),\n",
    "        \"nc\": len(class_names),\n",
    "        \"names\": class_names\n",
    "    }\n",
    "    \n",
    "    # Write YAML file\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"Dataset YAML configuration created at {yaml_path}\")\n",
    "    return yaml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef49860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Define YOLO training function with updated parameters\n",
    "def train_yolo_model(yaml_path, epochs=110, batch_size=16, img_size=640, patience=25, model_size='m'):\n",
    "    \"\"\"\n",
    "    Train YOLOv8 model for stenosis detection\n",
    "    \n",
    "    Args:\n",
    "        yaml_path: Path to dataset YAML file\n",
    "        epochs: Number of training epochs (updated to 110 as requested)\n",
    "        batch_size: Batch size for training\n",
    "        img_size: Image size for training\n",
    "        patience: Early stopping patience (updated to 25 for optimal results)\n",
    "        model_size: YOLOv8 model size ('n', 's', 'm', 'l', 'x')\n",
    "        \n",
    "    Returns:\n",
    "        Path to best weights\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    model = YOLO(f'yolov8{model_size}.pt')\n",
    "    \n",
    "    # Train the model\n",
    "    print(f\"Training YOLOv8 model with {epochs} epochs, batch size {batch_size}, image size {img_size}...\")\n",
    "    print(f\"Early stopping patience: {patience}\")\n",
    "    \n",
    "    # Define output directory paths\n",
    "    output_dir = os.path.join(\"coronary_stenosis\", \"yolov8_stenosis_detector\")\n",
    "    weights_dir = os.path.join(output_dir, \"weights\")\n",
    "    \n",
    "    model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=epochs,\n",
    "        batch=batch_size,\n",
    "        imgsz=img_size,\n",
    "        patience=patience,  # Updated early stopping patience for optimal results\n",
    "        project=\"coronary_stenosis\",\n",
    "        name=\"yolov8_stenosis_detector\",\n",
    "        exist_ok=True,\n",
    "        pretrained=True,\n",
    "        optimizer=\"SGD\",  # Use SGD optimizer\n",
    "        cos_lr=True,      # Cosine learning rate scheduler\n",
    "        amp=True,         # Mixed precision training\n",
    "        hsv_h=0.015,      # HSV hue augmentation\n",
    "        hsv_s=0.7,        # HSV saturation augmentation\n",
    "        hsv_v=0.4,        # HSV value augmentation\n",
    "        degrees=10.0,     # Rotation augmentation\n",
    "        scale=0.5,        # Scale augmentation\n",
    "        flipud=0.5,       # Vertical flip augmentation\n",
    "        fliplr=0.5,       # Horizontal flip augmentation\n",
    "        mosaic=1.0,       # Mosaic augmentation\n",
    "        mixup=0.1,        # Mixup augmentation\n",
    "        plots=True,       # Generate plots to monitor training\n",
    "    )\n",
    "    \n",
    "    # Find the best weights file directly\n",
    "    best_weights_path = os.path.join(weights_dir, \"best.pt\")\n",
    "    \n",
    "    # Verify if the file exists\n",
    "    if not os.path.exists(best_weights_path):\n",
    "        print(f\"Warning: Best weights file not found at {best_weights_path}\")\n",
    "        # Try to find the last weights as a fallback\n",
    "        last_weights_path = os.path.join(weights_dir, \"last.pt\")\n",
    "        if os.path.exists(last_weights_path):\n",
    "            print(f\"Using last weights instead: {last_weights_path}\")\n",
    "            best_weights_path = last_weights_path\n",
    "    \n",
    "    print(f\"Training complete. Best weights saved at: {best_weights_path}\")\n",
    "    \n",
    "    # Plot Train vs Val Loss/Accuracy to monitor generalization\n",
    "    try:\n",
    "        results_csv = os.path.join(output_dir, \"results.csv\")\n",
    "        if os.path.exists(results_csv):\n",
    "            results_df = pd.read_csv(results_csv)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Plot training vs validation loss\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(results_df['              train/box_loss'], label='Train Loss')\n",
    "            plt.plot(results_df['              val/box_loss'], label='Val Loss')\n",
    "            plt.title('Train vs Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            \n",
    "            # Plot mAP metrics (as a proxy for accuracy)\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(results_df['metrics/mAP50(B)'], label='mAP50')\n",
    "            plt.plot(results_df['metrics/mAP50-95(B)'], label='mAP50-95')\n",
    "            plt.title('Model Performance (mAP)')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('mAP')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(RESULTS_DIR, \"train_vs_val_performance.png\"))\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"Train vs Val Loss/Accuracy plot created to help monitor how well the model generalizes during training.\")\n",
    "        else:\n",
    "            print(f\"Results file not found: {results_csv}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Train vs Val performance plot: {str(e)}\")\n",
    "    \n",
    "    return best_weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62413ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Define main function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the complete pipeline\n",
    "    \"\"\"\n",
    "    print(\"Starting Coronary Stenosis Detection and Classification Pipeline\")\n",
    "    \n",
    "    # Define global constants if they aren't already defined\n",
    "    global BASE_DIR, YOLO_DIR, PROCESSED_DIR, RESULTS_DIR\n",
    "    \n",
    "    # Use relative paths - with fallback for Jupyter notebooks\n",
    "    try:\n",
    "        BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        # We're in a Jupyter notebook\n",
    "        BASE_DIR = os.path.abspath('.')\n",
    "    \n",
    "    YOLO_DIR = os.path.join(BASE_DIR, \"dataset\", \"yolo_format\")\n",
    "    PROCESSED_DIR = os.path.join(BASE_DIR, \"dataset\", \"processed\")\n",
    "    RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "    \n",
    "    # Create necessary directories\n",
    "    os.makedirs(YOLO_DIR, exist_ok=True)\n",
    "    os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Convert COCO format to YOLO format\n",
    "    convert_all_datasets()\n",
    "    \n",
    "    # Step 2: Preprocess dataset\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        input_dir = os.path.join(YOLO_DIR, split)\n",
    "        output_dir = os.path.join(PROCESSED_DIR, split)\n",
    "        \n",
    "        if os.path.exists(input_dir):\n",
    "            preprocess_dataset(input_dir, output_dir, split=\"\", target_size=(640, 640), convert_to_gray=False)\n",
    "        else:\n",
    "            print(f\"Warning: Input directory {input_dir} not found. Skipping preprocessing for {split}.\")\n",
    "    \n",
    "    # Step 3: Augment training data\n",
    "    train_images_dir = os.path.join(PROCESSED_DIR, \"train\", \"images\")\n",
    "    train_labels_dir = os.path.join(PROCESSED_DIR, \"train\", \"labels\")\n",
    "    augmented_images_dir = os.path.join(PROCESSED_DIR, \"train_augmented\", \"images\")\n",
    "    augmented_labels_dir = os.path.join(PROCESSED_DIR, \"train_augmented\", \"labels\")\n",
    "    \n",
    "    if os.path.exists(train_images_dir) and os.path.exists(train_labels_dir):\n",
    "        os.makedirs(os.path.join(PROCESSED_DIR, \"train_augmented\"), exist_ok=True)\n",
    "        os.makedirs(augmented_images_dir, exist_ok=True)\n",
    "        os.makedirs(augmented_labels_dir, exist_ok=True)\n",
    "        \n",
    "        augment_data(train_images_dir, train_labels_dir, augmented_images_dir, augmented_labels_dir, augmentation_factor=3)\n",
    "    else:\n",
    "        print(\"Warning: Training images or labels not found. Skipping data augmentation.\")\n",
    "    \n",
    "    # Step 4: Create dataset YAML\n",
    "    yaml_path = os.path.join(PROCESSED_DIR, \"dataset.yaml\")\n",
    "    create_dataset_yaml(\n",
    "        base_dir=BASE_DIR,\n",
    "        train_path=os.path.join(PROCESSED_DIR, \"train_augmented\") if os.path.exists(os.path.join(PROCESSED_DIR, \"train_augmented\")) else os.path.join(PROCESSED_DIR, \"train\"),\n",
    "        val_path=os.path.join(PROCESSED_DIR, \"val\"),\n",
    "        test_path=os.path.join(PROCESSED_DIR, \"test\"),\n",
    "        yaml_path=yaml_path\n",
    "    )\n",
    "\n",
    "    # Step 5: Train YOLOv8 model with updated parameters\n",
    "    yolo_weights = train_yolo_model(\n",
    "        yaml_path=yaml_path,\n",
    "        epochs=110,  # Updated to 110 epochs as requested\n",
    "        batch_size=16,\n",
    "        img_size=640,\n",
    "        patience=25,  # Updated patience for optimal results\n",
    "        model_size='m'\n",
    "    )\n",
    "\n",
    "# Cell 11: Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
